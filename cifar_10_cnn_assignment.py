# -*- coding: utf-8 -*-
"""CIFAR-10-CNN-assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qw9JPYwLZP8NLS1Wk_H5iCo0Ipv_R58P

#Importing necessary libearies
"""

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten
from keras.utils import to_categorical
import numpy as np
import pandas as pd

"""##Load the dataset"""

(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()
x_train.shape

x_test.shape

y_train.shape

"""##Here we see there are 50000 training images and 1000 test images"""

y_train[:5]

y_train = y_train.reshape(-1)
y_train[:5]

classes = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]

classes[8]

x_train[0]

"""##Let's plot some images to see what they are"""

plt.imshow(x_train[0])

plt.imshow(x_train[2])

def plot_sample(x, y, index):
    plt.figure(figsize = (15,2))
    plt.imshow(x[index])
    plt.xlabel(classes[y[index]])

plot_sample(x_train, y_train, 0)

plot_sample(x_train, y_train, 1)

plot_sample(x_train, y_train, 3)

"""###Normalizing the training data"""

x_train[0]/255

"""##Normalizing the values"""

x_train = x_train / 255
x_test = x_test / 255

"""##Building simple artificial neural network for image classification"""

ann = models.Sequential([
        layers.Flatten(input_shape=(32,32,3)),
        layers.Dense(3000, activation='relu'),
        layers.Dense(1000,activation='relu'),
        layers.Dense(10, activation= 'sigmoid')
      ])

ann.compile(optimizer= 'SGD',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy'])
ann.fit(x_train, y_train, epochs=5)

"""##You can see that at the end of 5 epochs, accuracy is at around 49%"""

from sklearn.metrics import confusion_matrix , classification_report
import numpy as np
y_pred = ann.predict(x_test)
y_pred_classes = [np.argmax(element) for element in y_pred]

print("Classification Report: \n", classification_report(y_test, y_pred_classes))

"""##Now let us build a convolutional neural network to train our images"""

cnn = models.Sequential([
        #cnn
        layers.Conv2D(filters=32, kernel_size=(3,3), activation= 'relu', input_shape=(32,32,3)),
        layers.MaxPooling2D((2,2)),
        layers.Conv2D(filters=32, kernel_size=(3,3), activation= 'relu', input_shape=(32,32,3)),
        layers.MaxPooling2D((2,2)),

        #dense

        layers.Flatten(),
        layers.Dense(64,activation='relu'),
        layers.Dense(10, activation= 'softmax')
      ])

cnn.compile(optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy'])

cnn.fit(x_train, y_train, epochs=10)

"""###With CNN, at the end 5 epochs, accuracy was at around 69% which is a significant improvement over ANN. CNN's are best for image classification and gives superb accuracy. Also computation is much less compared to simple ANN as maxpooling reduces the image dimensions while still preserving the features"""

cnn.evaluate(x_test, y_test)

y_test[:5]
#2 dimension array

"""###converting into 1 dimension array"""

y_test= y_test.reshape(-1)
y_test[:5]

plot_sample(x_test, y_test, 1)

y_pred= cnn.predict(x_test)
y_pred[:5]

y_classes= [np.argmax(element) for element in y_pred]
y_pred_classes[:5]

y_test[:5]

plot_sample(x_test, y_test, 3)

classes[y_classes[3]]

print("Classification Report: \n", classification_report(y_test, y_classes))